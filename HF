import torch
from torch.functional import Tensor
import torch.nn as nn
from functools import partial
import math
import warnings
import torch.nn.functional as F
from einops import rearrange, repeat
from torch import einsum
import numpy as np
from math import exp

class SlimmableConv2d(nn.Conv2d):
    def __init__(self, in_channels_list, out_channels_list, kernel_size=3, stride=1, padding=(1, 1), dilation=1, bias=False):
        super(SlimmableConv2d, self).__init__(in_channels_list, out_channels_list, kernel_size=3, stride=1, padding=(1, 1), dilation=1, bias=False)

        self.width_mul = 1
        self.in_channels_list = in_channels_list
        self.out_channels_list = out_channels_list

    def forward(self, input):
        if self.in_channels > 3:
            self.in_channels = int(self.in_channels_list * self.width_mul)
        self.out_channels = int(self.out_channels_list * self.width_mul)

        weight = self.weight[:self.out_channels, :self.in_channels, :, :]
        if self.bias is not None:
            bias = self.bias[:self.out_channels]
        else:
            bias = self.bias

        y = nn.functional.conv2d(input, weight, bias, self.stride, self.padding)
        return y
def get_kernel(k=16, sigma=1, mu=0):     # nsig 标准差 ，kernlen=16核尺寸
    gauss1D = np.linspace(-1,1,k)
    x, y = np.meshgrid(gauss1D, gauss1D)
    distance = (x**2 + y**2)**0.5
    gauss2D = np.exp(-(distance-mu) **2 / (2*sigma**2) )
    gauss2D = gauss2D / (2 * np.pi * sigma ** 2)

    gauss2D = gauss2D / np.sum(gauss2D)
    return gauss2D


class GaussianBlurConv(nn.Module):
    def __init__(self, channels=3, ks=3, sigma=1):
        super(GaussianBlurConv, self).__init__()
        self.channels = channels
        kernel = get_kernel(k=ks, sigma=sigma)

        kernel = torch.FloatTensor(kernel).unsqueeze(0).unsqueeze(0)
        kernel = np.repeat(kernel, self.channels, axis=0)
        self.weight = nn.Parameter(data=kernel, requires_grad=False)

        self.pad = nn.ReflectionPad2d(ks//2)

    def __call__(self, x):
        x = self.pad(x)
        x = F.conv2d(x, self.weight, padding=0, groups=self.channels)
        return x


class SELayer(nn.Module):
    def __init__(self, channel):
        super(SELayer, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Conv2d(channel, channel, kernel_size=1, stride=1,padding=0, bias=False),
            nn.ReLU(inplace=True),
            nn.Conv2d(channel, channel, kernel_size=1, stride=1,padding=0, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.avg_pool(x)#.view(b, c)
        y = self.fc(y).view(b, c, 1, 1)
        return y * x


class Head(nn.Module):
    """ Head consisting of convolution layers
    Extract features from corrupted images, mapping N3HW images into NCHW feature map.
    """

    def __init__(self, in_channels, out_channels):
        super(Head, self).__init__()

        self.conv1 = GhostConv1(out_channels, out_channels, stride=2)
        self.conv2 = GhostConv1(out_channels, out_channels, stride=2)

        self.GF = GaussianBlurConv(ks=5, sigma=10)
        self.conv01 = nn.Conv2d(3, out_channels//2, kernel_size=3, stride=1, padding=1, bias=True)
        self.conv02 = nn.Conv2d(3, out_channels//2, kernel_size=3, stride=1, padding=1, bias=True)
        # self.conv03 = nn.Conv2d(3, out_channels//8, kernel_size=3, stride=1, padding=1, bias=True)
        # self.conv04 = nn.Conv2d(3, out_channels//8, kernel_size=3, stride=1, padding=1, bias=True)

    def forward(self, x):
        x1 = self.GF(F.upsample_bilinear(x, scale_factor=1 / 16))
        # x2 = self.GF(F.upsample_bilinear(self.GF(F.upsample_bilinear(x1, scale_factor=1 / 4)), x.shape[2:]))
        x1 = F.upsample_bilinear(x1, x.shape[2:])

        x2 = x - x1

        x1 = self.conv01(x1)
        x2 = self.conv02(x2)
        # x3 = self.conv03(x3)
        # x4 = self.conv04(x4)

        F0 = torch.cat((x1, x2), 1)

        # F0 = F.relu(self.conv0(x))
        F1 = F.relu(self.conv1(F0))
        F2 = F.relu(self.conv2(F1))

        return [F0, F1, F2]

class Tail(nn.Module):
    def __init__(self, in_channels):
        super(Tail, self).__init__()

        self.conv0 = GhostConv1(in_channels*2, in_channels)
        self.conv1 = GhostConv1(in_channels * 2, in_channels)
        self.conv2 = nn.Conv2d(in_channels, 3, kernel_size=3, stride=1, padding=1, bias=True)

    def forward(self, res,  x):
        [F0, F1, F2] = x
        out0 = F.relu(self.conv0(torch.cat((F1, F.interpolate(F2, F1.shape[2:], mode='bilinear')), 1)))
        out1 = F.relu(self.conv1(torch.cat((F0, F.interpolate(out0, F0.shape[2:], mode='bilinear')), 1)))
        out = self.conv2(out1)

        out = res + out
        out = out.clamp(0, 1)
        return out, [out0, out1]

class GhostConv(nn.Module):
    def __init__(self, inchannels, channels,kernel_size=3, stride=1, padding=1):
        super(GhostConv, self).__init__()
        self.channels = channels
        self.conv1 = nn.Conv2d(inchannels, channels // 2, kernel_size=kernel_size, stride=stride, padding=1*(kernel_size -1)//2, dilation=1, bias=True)
        self.conv2 = nn.Conv2d(channels // 2, channels // 4, kernel_size=kernel_size, stride=1, padding=1*(kernel_size -1)//2, dilation=1, bias=True)
        self.conv3 = nn.Conv2d(channels // 4, channels // 8, kernel_size=kernel_size, stride=1, padding=1*(kernel_size -1)//2, dilation=1, bias=True)
        self.conv4 = nn.Conv2d(channels // 8, channels // 8, kernel_size=kernel_size, stride=1, padding=1*(kernel_size -1)//2, dilation=1, bias=True)

        # self.conv1x1 = nn.Conv2d(channels, channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)
        self.se1 = SELayer(channels // 2)
        self.se2 = SELayer(channels // 4)
        self.se3 = SELayer(channels // 8)
        self.se4 = SELayer(channels // 8)

    def forward(self, x):
        B = x.shape[0]
        x1 = self.conv1(x)
        x2 = F.relu(self.conv2(x1))
        x3 = F.relu( self.conv3(x2))
        x4 = F.relu( self.conv4(x3))
        feas = torch.cat((x1, x2, x3, x4), 1)
        # feas = feas.view(B, 4,  self.channels//4, x.shape[2], x.shape[3])

        x1_se = self.se1(x1)
        x2_se = self.se2(x2)
        x3_se = self.se3(x3)
        x4_se = self.se4(x4)

        attention = torch.cat((x1_se, x2_se, x3_se, x4_se), 1)
        # attention = x_se.view(B, 4, self.channels // 4, 1, 1)
        #
        # attention = F.softmax(attention, dim=1)
        out = feas * attention
        #
        # for i in range(4):
        #     fs = feats[:, i, :, :, :]
        #     if i==0:
        #         out = fs
        #     else:
        #         out = torch.cat((fs, out), dim=1)

        return out

class GhostConv1(nn.Module):
    def __init__(self, inchannels, channels, stride=1):
        super(GhostConv1, self).__init__()

        self.conv1 = nn.Conv2d(inchannels, channels // 2, kernel_size=3, stride=stride, padding=1, bias=True)
        self.conv2 = nn.Conv2d(channels // 2, channels // 4, kernel_size=3, stride=1, padding=1, bias=True)
        self.conv3 = nn.Conv2d(channels // 4, channels // 8, kernel_size=3, stride=1, padding=1, bias=True)
        self.conv4 = nn.Conv2d(channels // 8, channels // 8, kernel_size=3, stride=1, padding=1, bias=True)

        # self.conv11 = nn.Conv2d(channels // 2, channels // 2, kernel_size=1, stride=1, padding=0, bias=True)
        # self.conv21 = nn.Conv2d(channels // 4, channels // 4, kernel_size=1, stride=1, padding=0, bias=True)
        # self.conv31 = nn.Conv2d(channels // 8, channels // 8, kernel_size=1, stride=1, padding=0, bias=True)
        # # self.conv41 = nn.Conv2d(channels // 8, channels // 8, kernel_size=1, stride=1, padding=0, bias=True)

    def forward(self, x):
        x1 = self.conv1(x)
        x2 = self.conv2((F.relu(x1)))
        x3 = self.conv3((F.relu(x2)))
        x4 = self.conv4((F.relu(x3)))

        x = torch.cat((x1, x2, x3, x4), 1)

        return x

class ResBlockWoAC(nn.Module):
    def __init__(self, inchannels, outchannels):
        super(ResBlockWoAC, self).__init__()

        self.conv1 = GhostConv1(inchannels, outchannels)
        self.conv = GhostConv1(outchannels, outchannels)

        self.se = SELayer(outchannels)

    def forward(self, x):
        residual = x
        out = F.relu(self.conv1(x))
        out = self.conv(out)
        out = self.se(out)
        out = residual + out

        return out


class RepHazeNetWAC(nn.Module):
    def __init__(self, channels=64, Nblks=6):
        super(RepHazeNetWAC, self).__init__()

        self.Blocks = nn.ModuleList([ResBlockWoAC(channels, channels) for _ in range(Nblks)])

        self.head = Head(channels, channels)
        self.tail = Tail(channels)

        # self.fusion = GhostConv(channels*Nblks,  channels, kernel_size=1,padding=0)
        # self.KD = nn.ModuleList([nn.Conv2d(channels, channels, kernel_size=1, stride=1, padding=0, bias=False) for _ in range(6)])

    def forward(self, x):
        res = x
        [F0, F1, F2] = self.head(x)

        Fs = [F0, F1, F2]
        for i in range(len(self.Blocks)):
            F2 = self.Blocks[i](F2)

            Fs.append(F2)

        # F2 = self.fusion(torch.cat(Ft, 1))
        x, [out0, out1] = self.tail(res, [F0, F1, F2])
        Fs.append(out0)
        Fs.append(out1)
        return x, Fs
